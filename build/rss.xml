<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Charles' Lab Notes</title>
    <link>https://notes.inclouds.space/</link>
    <atom:link href="https://notes.inclouds.space/rss.xml" rel="self" type="application/rss+xml" />
    <description>Charles' quick-to-publish notes</description>
    <language>en-us</language>
      <item>
        <title># 2023-08-27</title>
        <description>Not a lot to update; I&#39;m traveling in Germany and Austria for a few weeks.

Before leaving, [Jinny](https://jinnycho.github.io/) and I made a clone of the
Wavelength board game in Folk:

&lt;div class=&#39;vimeo-embed&#39; style=&quot;padding:56.25% 0 0 0;position:relative;&quot;&gt;&lt;iframe
src=&quot;https://player.vimeo.com/video/858421711?badge=0&amp;amp;autopause=0&amp;amp;player_id=0&amp;amp;app_id=58479&quot;
frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen; picture-in-picture&quot; allowfullscreen
style=&quot;position:absolute;top:0;left:0;width:100%;height:100%;&quot;
title=&quot;IMG_2270&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;script
src=&quot;https://player.vimeo.com/api/player.js&quot;&gt;&lt;/script&gt;

I&#39;ve been writing [an expect test
libray](https://github.com/charlesetc/expect-def) for Python. I&#39;ve been writing
python for my part-time work recently and am trying to get it to a place I&#39;m
happy with. I am beginning to understand why it&#39;s been so popular. I&#39;m hoping
to develop better editor integration, to make things feel a bit more dynamic,
minimal, malleable. The expect tests feel like a step in the right direction!
We&#39;ll see how it goes.

One very pleasantly surprising thing was the ease of releasing a pip package
with [hatch](https://hatch.pypa.io/latest/). Things took a lot less time and
frustration compared to with OCaml.

I also went to a woodworking class yesterday!

![](./static/woodworking.jpg)

Tried to make some gears (the goal was to the number of times a handle had been
rotated) but they were not as precise as necessary!

And lastly I bought a mechanical watch at a flee market today:

![](./static/mech-watch.jpeg)

It runs but I&#39;m not sure how to set it. I think I&#39;ll order some screwdrivers to try to dis-and-reassemble it. 

![](./static/inside-watch.jpg)

TschÃ¼ss!</description>
        <guid isPermaLink="false">inclouds-space-20230827</guid>
      </item>

      <item>
        <title># 2023-08-14</title>
        <description>Things are going well! I&#39;ve starting contracting part-time. It&#39;s really nice to
have some money in so I can live life a bit more calmly while continuing to work
on creative projects in my free time. Not every project has to be a money-making
opportunity.

So I&#39;ve gotten super into watchmaking and clockmaking youtube videos. There&#39;s
something about beautifully crafted gold and silver intricate bejeweled
movements that just really absorbs my attention. Definitely an &quot;ooh shiney!&quot;
kind of thing. It&#39;s amazing to me that these craftspeople are able to turn some
hunks of metal, a couple rubies, and maybe a spring into a working timepiece. So
I&#39;ll probably be thinking more about that going forward.

I&#39;ve been working on / thinking about a video game recently as well. In an
utterly predictable turn of events, this has mostly amounted to lua tooling
*around* the video game so far. I mentioned last time an expect test library for
lua. I&#39;ve since used this to build and test a folk-style claim/when system for
lua. (The
[tests](https://github.com/charlesetc/starlight/blob/main/test/rivulet.lua) are
probably the easiest way to see what it tries to achieve.)

I was surprised that when I went to go and use this claim/when system in a game,
I wasn&#39;t very excited by it. Maybe it&#39;s because everything was early days, but
it seemed like the logic I was expressing could have been written a lot more
easily by just having some variables in scope and running functions against
them, instead of orchestratic an incremental evaluation system. Part of the
problem, maybe, is that the syntax for `when`-ing and `claim`-ing is
substantially heavierweight in lua than in Folk for instance. I might try to
iterate a bit on the interface to see if it can be easier to work with.

Also the last few days I&#39;ve gotten nerdsniped by
[redbean.dev](https://redbean.dev). It&#39;s an incredible piece of engineering
hackery that allows the same executable (and somehow also zip file?) to run on
any x86 computer. It&#39;s a portable local execution environment with sqlite and
lua built-in. I have a dream of turning it into a smalltalk-esque local-first
user interface editor for the web. Maybe even as part of the game? Stay tuned.

Lastly, I want to leave you with an imploring: Why o why can&#39;t there be chunky
laptops on the market? Laptops are thin enough! I don&#39;t care about eeking the
last few millimeters out of a potential lap computer, I would much rather save
on price, battery life, or performance and embrace the chunky aesthetic.
Panasonic makes a wonderfully [well-built computer](https://na.panasonic.com/us/computers-tablets-handhelds/computers/laptops/toughbook-40)
that might be a bit extreme but certainly something of value. If only it wasn&#39;t
$4000 of value!</description>
        <guid isPermaLink="false">inclouds-space-20230814</guid>
      </item>

      <item>
        <title># 2023-07-27</title>
        <description>The last few weeks I&#39;ve been learning more microcontroller things and
playing with Lua some more!

## Watch

I&#39;ve been playing with the [LilyGo
AMOLED](https://www.lilygo.cc/products/t-display-s3-amoled) controller:
basically an esp32 with a really high quality screen attached.

I have an idea for a watch that would combine the internal module of a [Casio
F91W](https://www.casio.com/us/watches/casio/product.F-91W-1/) with this LilyGo
microcontroller to produce a hackable smartwatch that can always tell you the
time. (The watch bit runs on its own coin cell battery that lasts 10 years.)

Here&#39;s the &quot;prototype&quot;:

![](./static/watch-07-27.jpeg)

## Lua: Tests + Incremental Engine

Outside of hardware hacking, I&#39;ve been writting some more Lua. I&#39;m trying to
re-create the claim/when system from Folk as a Lua DSL. Along the way, I&#39;ve
written an expect-test-style testing framework for Lua
([code](https://github.com/charlesetc/starlight/blob/main/expect.lua),
[example](https://github.com/charlesetc/starlight/blob/main/test/expect.lua)).

I want to broadcast this (again): **Expect tests are by far the best way to write unit tests.**

I&#39;ve written a bit about this [here](https://inclouds.space/blog/expect-tests/)
but I would actually recommend Jane Street&#39;s [recent
article](https://blog.janestreet.com/the-joy-of-expect-tests/) on the subject (by the wonderful [James Somers](https://jsomers.net/)!)

Basically: When you write unit tests you have to write out the data you expect
to exist after the test. When the desired output changes, you have to change
the assertions made in the code. Expect tests automate this: instead of
manually writing assertions, you simply print values within the test and the
framework makes the assertion that whatever was printed is the same as the last
accepted run. A test fails when it prints something differently, but it&#39;s
trivial to accept the new output as correct if the desired behaviour has
changed. Just really convenient! 

So yeah now I can happily write tests in Lua!

The actual claim/when framework needs a bit more work but it&#39;s getting close to
being a nice incremental evaluator. The idea is then to use it for the basis of
a video game, just for fun.

## Weird E-ink Solar-panel Computer 

I&#39;ve also been doing some research (with a friend of mine) into creating a
solar-powered computing device. The idea would be to turn on a microcontroller
every hour for a few seconds, update a integrated e-ink screen, and then shut
off. Ideally a tiny-enough amount of energy in the process to run the whole
thing from the a super capacitor attached to an indoor solar panel.
Conventional solar panels are made for direct outdoor sunlight exposure, but
there is a growing class of products that are optimized for indoor light.
[Epishine](https://www.epishine.com/) has a product on the market that seems
like it would do nicely. I&#39;m waiting for some parts to be available, but
hopefully within a month I&#39;ll be able to order the supplies!</description>
        <guid isPermaLink="false">inclouds-space-20230727</guid>
      </item>

      <item>
        <title># 2023-07-10</title>
        <description>I was on vacation last week. Just getting back in the flow today. Some things to
share:

## Electronics

I&#39;ve started programming microcontrollers lately! Just the basics, making lights
blink and such. I made a game with four buttons and four lights here:

&lt;div class=&#39;vimeo-embed&#39; style=&quot;padding:56.25% 0 0 0;position:relative;&quot;&gt;&lt;iframe
src=&quot;https://player.vimeo.com/video/843984280?badge=0&amp;amp;autopause=0&amp;amp;player_id=0&amp;amp;app_id=58479&quot;
frameborder=&quot;0&quot; allow=&quot;autoplay; fullscreen; picture-in-picture&quot; allowfullscreen
style=&quot;position:absolute;top:0;left:0;width:100%;height:100%;&quot;
title=&quot;IMG_2270&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;script
src=&quot;https://player.vimeo.com/api/player.js&quot;&gt;&lt;/script&gt;

It&#39;s been really fun learning this stuff. The nicest thing to discover is that
simple things aren&#39;t actaully hard at all! It always seemed like things
involving hardware were going to be very low-level and difficult, but it&#39;s
actually quite easy to plug a microcontroller into your computer and upload some
code that blinks a light or listens to some buttons.

You can see the code for the above game
[here](https://gist.github.com/charlesetc/89fb69c93c505deed35bd77c0be384dd).

Already it seems like there are so many possibilities of things to make in the
real world. Very excited for what&#39;s to come.

## Apricot

I [published](https://inclouds.space/blog/apricot) [Apricot](https://apricot.sh)
the other day! It was nice to get something out there and I was surprised by the
positive reception. It is good to be reminded that people can care about and be
impacted by the things that happen on two dimensional rectangular screensâ€”not
everything has to be in the real world ðŸ¤” 

## Next?

Lately I&#39;ve been selecting for interestingness and, quite correlated, learning.
Now it&#39;s started to feel like there are a lot of cool projects to work on, and
at the same time, maybe I don&#39;t have to spend *all* of my time working on the
most interesting? Doing so ends up segmenting my time a lot â€”the most
interesting thing can change hour-to-hour. It might be time for another round of
deep work on one or two project that I care about...</description>
        <guid isPermaLink="false">inclouds-space-20230710</guid>
      </item>

      <item>
        <title># 2023-06-29</title>
        <description>## Interaction Design Paper

I read a great paper today! [How Bodies Matter: Five Themes for Interaction Design](./static/how-bodies-matter.pdf) It&#39;s very much in line with the work we&#39;ve been doing at Folk, giving structure and words to the motivation for the infusion of the physical world with computation and vice versa.

There&#39;s a section therein that I wanted to speak to: &quot;Risk&quot;. The authors make the very insightful point that real world interfaces often have more risk associated with them: once you make a action there is no way to un-make that action. Virtual interfaces on the other hand often try to enable free history traversal. This risky commitment to action or lack thereof can profoundly impact the attitude of the actor:

&gt; Situations of higher risk cause people to feel more emotionally negative and, therefore, more focused, paying closer attention to detail, while situations of low risk allow people to feel more emotionally positive, relaxed, curious, and creative.

It&#39;s valuable to think about what we give up when we move to a risk-free way of interacting with the world. There are probably circumstances where it&#39;s valuable to build and use tools that embrace this sort of focus-inducing risk.

*However* I try to encourage and embrace emotionally positive, curious, and creative mindsets with the tools that I build. This is one of the reasons I love technology: it has the potential to induce these mindsets. Reading this paper, you might think that moving more to the physical world might necessitate taking on more risk in your actions and therefore encounter less coziness in more physically-centered tools. But I have found the opposite to be true:

- the Folk system we&#39;re building actually has *more* undo-ability and state agnosticism than traditional digital tools, not less. The vast majority of the computation going on is a pure function of the physical state of the system you&#39;re working with. So while traditional user interfaces might not always make clear *how* to undo or the path of actions back-track along, in Folk it&#39;s just a matter of where you put items on the table. This actually amplifies the sense of safety that digital tools are capable of creating, even while bringing in more embodied interaction.
- and working with physical objects in the real worldâ€”particularly those which are well-designed and texturedâ€”can be a very cozy experience. Especially compared to the traditional harsh physicality of a computer. 

## Writing idea

I had an idea for a blog post recently. Instead of trying to formalize an argument for these sorts of physical computing interfaces I&#39;ve been exploring, I could write a post arguing *against* this kind of theory. That is, trying to outline a generally good-faith position that humans are very good at symbolic processing and thus traditional coding interfaces are superior, that the keyboard and multi-button mouse paradigm is a highly efficient interface far surpassing anything that can be done on a tabletop, etc.

This would be an interesting position to try to elucidateâ€” I&#39;m sure I would develop a more nuanced outlook in the processâ€”Â but I am also hoping that it would incite from the reader feirce critique against it and in favor of physical computing. People love being contrarians (myself included for sure) and this might just be the way to get them to join the cause.

## Book-binding

I&#39;ve taken to printing out papers recently on physical paper. I&#39;ve been using newsprint - a somewhat silkier paper that actually seems to hold up better under stress. I print out 2 pages per sheet, double-sided, and then fold and staple them into pamphlets ready to be grabbed on my way out the door. This makes for great subway reading! Photo here:

![](./static/paper.jpeg)

I really can&#39;t recommend this highly enough. It&#39;s such a nicer physical reading experience. It&#39;s creatively satisfying to produce a history of artifacts of my research. I even printed out a book this way (from a pdf available online), saving $30 plus shipping charges. Letting ourselves a moment of romance, we can glimpse into a society of widespread indie book production! Basically printing is 3d printing for books? Who&#39;d&#39;ve thought.</description>
        <guid isPermaLink="false">inclouds-space-20230629</guid>
      </item>

      <item>
        <title># 2023-06-28</title>
        <description>Today was a nice day of calm focus and research.

I am trying to learn more about electronics. My last project involed a
raspberry pi zero and an oled display that got soldered on poorly, so today I
purchased a solder sucker and two microcontrollers. I have a lot of ideas â€”
suprisingly many are time-related? desk clock, watch, physical timer, etc.

This sort of making is very motivating to me. I&#39;m not sure if it&#39;s art or what,
but the simple joy of practicing my own agency through creation and learning in
the process is just so wonderful. I&#39;m not sure where it&#39;ll take me this time,
but I&#39;m leaning into it. Hopefully somewhere interesting!

(In that vein, I found [this talk](https://www.youtube.com/watch?v=XVGVsdEuPBs) by [Chia](https://twitter.com/hotemogf) to be very inspiring.)

I also applied to work as a teacher at a Brooklyn coding school today. I&#39;ve
been reading a lot of education theory lately and am hoping to see what it&#39;s
like to work with children directly. I&#39;m guessing it&#39;d be super informative.

I also stumbled across what struck me as a lovely interactive piece of art
today. It&#39;s a demo for accessing the webcam with rust in the browser that just
so happens to pixelate in a beautiful way. I had a lot of fun dancing in front
of the camera, enjoying an interactive control of the light on the screen. Here&#39;s an example of w
is what it looks like (having tea at the time):

![](./static/pixel-tea.png)

I enjoyed this so much that I hosted a static version for y&#39;alls enjoyment:
[blocky.inclouds.space](https://blocky.inclouds.space)

It&#39;s just a static site right now but I&#39;m imagining a social network full of
people sharing small blocky clips! There seems to be [a web
api](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrackGenerator)
to create video in the brower but it&#39;s not supported by Firefox so I&#39;m afraid
that dream will have to wait. Though I might be able to [record an html
element](https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API/Recording_a_media_element)
to create a vidoe? 

Or maybe it could be fun to have a dedicated device (microcontroller + camera + display) in my house like this? Could be a nice artwork!

Anyways that&#39;s all for today! ðŸ’»âœ¨

P.S. I also came across [Clement Zheng&#39;s
work](https://clementzheng.info/Teaching) on the Folk discord and it so very cool on so many axes.</description>
        <guid isPermaLink="false">inclouds-space-20230628</guid>
      </item>

      <item>
        <title># 2023-06-21 (published 2023-06-26)</title>
        <description>## Neovim and Lua

Well last weekend was very fun! I completely revamped my editor setup -
switching to neovim with only lua plugins. I&#39;m extremely impressed by the
quality of this ecosystem. Especially compared to the vimscript ecosystem, I&#39;ve
had far fewer bugs, plugins conflicting with each other, latency
issues, etc. Plus the plugins don&#39;t seem to be bloated and the start times are
good! This has all happened just in the last couple of years! Well done lua
vimmers. Thank you.

I&#39;m curious how my software-building desires will change now that I have an
editor I like. I&#39;ve been leaning heavily towards the &#39;build the whole
editor up from scratch&#39; route. I could see myself doing some more neovim
integrations instead in the future?

## Folk

I&#39;ve been helping AndrÃ©s and Omar improve the folk system. We&#39;ve made a lot of
progress even if it&#39;s a bit slow! I&#39;m optimistic. There&#39;s a lot of work that
goes into real-time tracking. Most of the work has been on camera-projector
calibration and performance. The faster the system and the better-calibrated is
the more *__real__* it is. The illusion holds. And more: the idea communicates.
People can start to understand the power of this kind of system.  But yeah,
it&#39;s a lot of systems programming and debugging. 

## Physical interfaces

There are some fun routes I&#39;m exploring around physical interfaces to
computers:

##### 1. Monocle

I just ordered a [monocle](https://brilliant.xyz/products/monocle), a small AR
device that clips onto a camera frame. It&#39;s essentially a tiny oled display + a
prism + a camera + two touch sensors + a bluetooth chip + an FPGA + a battery +
a clip. What a bundle!

Basically this lets you augment a very small rectangle in your vision: drawing
some graphics or writing some text. It seems like the software is very much a
work in progress. I&#39;m not sure extent I&#39;ll be able to do with it, but I&#39;m
looking forward to finding out!

##### 2. Magnetic sheets

I also bought some magnetic sheets from Amazon yesterday. They are adhesive on
one side so my plan is to print out some words on paper, stick on the magnetic
sheets, and then cut out the words. Much like the refrigerator magnet poetry of
my youth! But this time it&#39;ll be Logo commands with camera recognition. That&#39;s
right! Stay tuned.

#### 3. Transparent Displays

The projector film arrived a couple days ago! I tested it out with the folk
system a bit, by placing a projector on the table pointing at me and positioning
a sheet of glass with the film between me and the table. It&#39;s pretty
interesting!

Basically: it&#39;s a transparent display! There are some air bubbles but I
would probably call that user error than anything else. Most of the films are
quite blurry at distances &gt; a few inches. One of them â€” the most transparent
â€” seems like it might be better in this regard.

What does this give you over just projecting onto a desk from above? That&#39;s the
question I&#39;m hoping to answer, I guess. I think the biggest answer so far is
that you don&#39;t have to worry about the topology of what you&#39;re projecting on:
the screen is flat and anything drawn to it will appear un-distorted above the
objects on the table.

I&#39;ll get some photos and videos of it up on this page sometime soon.</description>
        <guid isPermaLink="false">inclouds-space-20230621published20230626</guid>
      </item>

      <item>
        <title># 2023-06-16</title>
        <description>Update time! 

## Folk

I&#39;ve had a performance regression on my folk system, with the frame rate
dropping to something like 10. It&#39;s preventing me from experimenting with higher
level applications, since the kind of interaction that I was showing in my last
post is just terrible at 10fps. In the process of debugging!

I&#39;ve also been helping out to improve the calibration in Folk. One problem that
you get in projector-camera mapping systems like this is you often want to
project a graphic relative to something that the camera sees. But you don&#39;t know
a priori where the projector can project in terms of the camera. Hence,
projector-camera calibration: the process of mapping camera coordinates to
projector coordinates.

The way this works in Folk is it lights up each pixel of the projector uniquely,
paying close attention with the camera. But some pixels from the projector don&#39;t
get seen by the camera, so it picks just 4 points that are and then comes up
with a linear map using those 4 points between the projector space and the
camera space. Unfortunately this linear map doesn&#39;t work so well because the
distortion within the camera and projector isn&#39;t linear: there is radial
distortion in their lenses that aren&#39;t taken into account. So we&#39;ve been working
on coming up with a mapping that does take into account radial disortion. And
even more fun we&#39;re working on mapping into 3d coordinates as well. Since we
know the physical size the April tags, we can infer how high up they are in
space. More accurate and 3-dimensional calibration will let folk precisily
project onto various portions of a page, even when it&#39;s being held and moved
around in space. Very exciting!

I did write one higher-level primitive in folk: an &quot;operator&quot; card. Basically,
you can declare a card is an operator and then it&#39;ll get information about which
cards are to the immediate left or right of it. So you can have behaviour
defined by putting three cards down in an order. I&#39;m planning on using this for
doing a vector  addition demo in folk!

## Societal Attention

Also and unrelated: I&#39;ve been thinking about &quot;societal attention&quot;. There&#39;s this
concept we have of individual, human attention. Something gets brought up in an
individual&#39;s consciousness, and then they spend time thinking about that thing.
Those initial thoughts might lead to more thoughts and, well, this is the
process of paying attenion and thinking about something.

So I think there is an analogous phenomenon in human societes: something happens
and whole groups of people end up thinking about it. They think some thoughts,
share them around, prompting more thoughts. My insight here is that societies
can kind of get &quot;lost in thought&quot; the same way humans can: they can spend their
time thinking and talking about something, even if it doesn&#39;t end up being
useful or even if the original bits of information that sparked the discussion
were incorrect or mistaken.

Maybe it&#39;s worthwhile thinking about how we could short-circuit these kinds of
conversations once it&#39;s clear (to whom?) that they are no longer productive?
Maybe it just takes a lot of individuals carefully doing that in their own
thinking processes?

## Transparent Display

I got the projector films in the mail! I put them onto some glass and put the
glass in front of a projector, basically making a transparent display. Pretty
decent? It&#39;s a bit unclear what the possible applications would be. I&#39;ll try to
talk more about it in the future and share some links/photos in case anyone else
wants to try.</description>
        <guid isPermaLink="false">inclouds-space-20230616</guid>
      </item>

      <item>
        <title># 2023-06-09</title>
        <description>I wrote my first meaningful folk program! Its goal is to prove [Thales&#39; theorem](https://en.wikipedia.org/wiki/Thales%27s_theorem) by letting people interact with the pieces. Thale&#39;s theorem states that any triangle whose corners lie on the circumference of a circle and whose hypotenuse is the diameter of the circle is a right triangle. See for yourself:

&lt;video controls muted&gt;
  &lt;source src=&quot;https://raw.githubusercontent.com/charlesetc/lab-notes/video/build/static/folk-01.mov&quot; type=&quot;video/mp4&quot; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;</description>
        <guid isPermaLink="false">inclouds-space-20230609</guid>
      </item>

      <item>
        <title># 2023-06-08</title>
        <description>Smoke and (AR) mirrors in New York City.

I&#39;m happy to see a hype shift towards more HCI-related topics
and away from all AI all the time. AR relates more to my interests and,
while surely it has some distopian futures embedded in the discourse, it&#39;s at
  least not entirely centered around them.

A quick note on hype: I think people lose their minds when it comes to new
technology. New tech is cool and fun and often genuinely transformative! But at
any given time period those transformations are finite. Some things change, some
things don&#39;t. And we are bad at knowing what will and won&#39;t change `n` months
out. I try to be careful of claims with absolute certainty. We all need some
humility in times like these.

Anyways!

Apple&#39;s headset is cool â€” especially the eye tracking!
We&#39;ve never seen it in mainstream tech hardware before. I&#39;m really excited
for the possibilities. Though I don&#39;t think I&#39;ll rush to build an app for it.
I&#39;m much more excited about projectors! The ability for tech to actually
*augment* the world without taking away my ability to engage with the people
therein. So important!

This brings me to [Folk](https://folk.computer). I&#39;ve been volunteering a little
with the team, getting a home instance set up, and it&#39;s finally working!

1. It&#39;s much faster than I was expecting. Very satisfying to play with. I think
   I&#39;m getting around 30 frames per second. I don&#39;t think 60 is that far away
   and that&#39;s even more exciting.
2. I&#39;ve been experimenting with different paper types and sizes. I was very
   pleasantly surprised by newsprint! Mine has a great kind of soft-glossy
   texture, stacks well since it&#39;s so thin, and has more of an e-ink color compared to
   normal bright white paper. Also, suprisingly durable! I&#39;ve been cutting it to
   approximately A6 size for now and I like that much better than letter or
   half-letter: there&#39;s room for more cards to fit under the relatively small
   projection space on my desk.
3. I&#39;ve been thinking about what I would want to build with this sort of
   interface. There&#39;s the question of &quot;are the papers cenceptualized as *the
   thing* you are manipulating or are they handles to an explicitely virtual
   object?&quot;. Maybe the answer has to be: both depending on the context, but
   favor *the thing* when possible.
4. I&#39;m torn about the english-like regex pattern matching syntax, which is used to read
   and write from the Folk in-memory reactive database. On the one
   hand, I do like the idea that things are extensible, self-documenting,
   accessible, etc. But it is a bit verbose at times and there is very little
   error information when you mistype something. 
   Better tooling might help!
5. It&#39;s interesting that I already want *finer* inputs to the things that I&#39;m
   manipulating. I want to have a relative small circle drawn and then be able
   to attach small things to it and so on. This is not really easy to do given
   the size of April tags. There&#39;s some thought of switching to Bullseye
   feducials to get smaller feducial tracking, but you&#39;ll still
   have to worry about occluding tags with your hand. Electrical engineering to the rescue?
6. It&#39;s hard to know how much time to spend on the system itself or
learning how to build apps on top of it.

I also spent a good amount of time researching in-air (transparent) displays.
Been thinking about how to create a folk-like experience by positioning one
between the table and my head, using cameras for head-tracking.

There are two ways I was thinking of doing this:

1. Find an LCD display, peel of the backing, and then hopefully get a
   transparent LCD display panel.
2. Project onto a piece of glass with a film on it that is suspended between you
   and a table with objects.

Turns out that LCDs are quite dark even with the backing peeled off and need a
backlight to really shine, making projection still the way to go.

So I got some samples of the film shipped to me, bought a glass panel,
some brass rods, and another ikea task lamp! Maybe this will turn into something
cool!</description>
        <guid isPermaLink="false">inclouds-space-20230608</guid>
      </item>

      <item>
        <title># 2023-06-05</title>
        <description>Some highlights from the past few days:

1. Continued work on the folk setup. Calibration between the camera and
   projector isn&#39;t working, still have to investigate that today. But I got a
   wifi adapter so no hotspotting for me anymore!
2. [HTML energy](https://twitter.com/rsnous/status/1665126377144590341) event
   on saturday. Really fun to see people congregate to make digital art!
3. I&#39;ve been getting really into lua and hammerspoon recently. Made a
   keybinding to let me quickly open these lab notes, for instance! It&#39;s fun to
   think of my computer as a display mechanism underneath a pile of lua.
4. In the course of this lua splurge, I wanted to execute a program in a
   directory *without* using a shell to `cd` there first. It feels like this
   should be a built-in utility! Like how you can set an environment variable
   with `env THIS=THAT`. So I made it! It lets you `exec-in a-directory
   your-executable your-arguments`. Worked great! Maybe there&#39;s something else
   that does it? It was kind of fun to write â€” I wrote the bash first and then
   asked an LLM to convert it to C for me. [github
   ](https://github.com/charlesetc/utils/tree/main/exec-in)
5. I&#39;ve been with [Justin](https://just-be.dev/) about making an in-air LCD display: completely
   transparent except when you want it to show something. Like an iPad for AR I
   suppose? I&#39;d be interested in combining these with cameras to make a sort of window into the
   augmented world.


&lt;pre&gt;---&lt;/pre&gt;

Update: Got calibration working and so the rectangles are now following the
april tags! The automatic calibration still isn&#39;t quite working, I had to manually
feed in some of the points that it came up with. And as you can see the
calibration isn&#39;t that good. But it&#39;s a starting point!

![](./static/IMG_2036.jpeg)

Also, bubble:

![](./static/IMG_2018.jpeg)</description>
        <guid isPermaLink="false">inclouds-space-20230605</guid>
      </item>

      <item>
        <title># 2023-05-31</title>
        <description>An awesome day. It started out by installing ubuntu on a small desktop computer:

![](./static/2023-05-31-01.jpeg)

And then progressed to drilling holes into a vesa mount of a monitor arm:

![](./static/2023-05-31-03.jpeg)

Which let me position a webcam and projector in the air:

![](./static/2023-05-31-04.jpeg)

To finally project a blue square on my desk:

![](./static/2023-05-31-02.jpeg)

And what a blue square it is!

There were too many issues to count along the way. The computer I got ended up not having a wifi card built in but it did come with a usb wifi adapter. I spent altogether too much time manually downloading the debian packages needed to compile this adapter&#39;s firmware only to find out that it wasn&#39;t compatible with the latest linux kernel version. So I&#39;m getting a new wifi adapter shipped, but in the meantime I went to the store to buy an ethernet cable. This got me started but it wouldn&#39;t reach to the right desk, so I have ended up tethering my phone&#39;s hotspot through a usb connection. Which of course lead to more issues. My printer is configured to work on my home network which this desktop computer doesn&#39;t have access to (since it doesn&#39;t have a wifi card), so printing out four April tags involved alternating between my phone&#39;s hotspot to get a single print job queued and then my home network to actually print it. A wild ride for sure!

But it should all be worth it soon.</description>
        <guid isPermaLink="false">inclouds-space-20230531</guid>
      </item>

      <item>
        <title># 2023-05-30</title>
        <description>I&#39;m in the process of setting up a [folk.computer](https://folk.computer) installation! Today involved running to the hardware store to buy clamps, eyewear, power strip, flash drive, etc. Tonight or tomorrow I&#39;ll start drilling: have to widen the holes in a monitor arm&#39;s VESA mount to let through the 1/4&quot; 20 screws that the projector and webcam use. I&#39;m hoping that the end result will be pretty clean!

Folk is a projector-camera &quot;physical computing&quot; interface and operating system developed by [AndrÃ©s](https://cwervo.com/) and [Omar](https://omar.website/). The idea is you position a camera and a projector above your desk and plug them into a computer with access to a printer. This setup lets you:

- use computer vision to track April Tags (kind of like QR codes but faster to recognize) in real time.
- project light onto and around the objects you are tracking, informed by information from the computer vision (position, rotation, skew of tags in space).
- print out sheets of paper with these April Tags, giving you the ability to bring new augmented objects into the world with ease.

I&#39;m extremely excited about this. Last week I witnessed a musical performance where someone with no particular training manipulated 5 pieces of paper to create a musical experience. This is how we seamlessly empower non-technical humans with technology: extraordinarily easy, high-bandwidth interfaces you can **play** with.

Stay posted.</description>
        <guid isPermaLink="false">inclouds-space-20230530</guid>
      </item>

      <item>
        <title># 2023-05-29</title>
        <description>I added links on each header here! Had to use pandoc&#39;s gfm_auto_identifiers extension and then used a [lua filter](https://pandoc.org/lua-filters.html) to add the actual links to the header. This was an updated version of [the filter](https://github.com/jgm/pandoc-website/blob/master/tools/anchor-links.lua) pandoc uses for its own documentation.

```lua
function Header(h)
  if h.identifier ~= &#39;&#39; then
    local anchor_link = pandoc.Link(
      h.content,                        -- content
      &#39;#&#39; .. h.identifier,              -- href
      &#39;&#39;,                               -- title
      { class = &#39;header-anchor&#39; }       -- attributes
    )
    h.content = anchor_link
    return h
  end
end
```</description>
        <guid isPermaLink="false">inclouds-space-20230529</guid>
      </item>

      <item>
        <title># 2023-05-28</title>
        <description>I&#39;ve added an RSS feed for these notes! I&#39;m using pandoc to render a single
markdown file into html, so had to figure out some way to get an rss feed as
well. I went with a ruby script to parse the markdown and generate the xml on
build. Turned out to be easier than I was expecting!

See the feed here: [./rss.xml](./rss.xml)</description>
        <guid isPermaLink="false">inclouds-space-20230528</guid>
      </item>

      <item>
        <title># 2023-05-27</title>
        <description>## Motivation

Well I&#39;ve been doing some long-form writing on my
[blog](https://inclouds.space/blog) and I&#39;ve enjoyed it. But the format
necessitates a lot of editing and care, at least in my mind. This can be good
for meâ€”practicing writing long form pieces and the editing that goes with
  thatâ€”but it&#39;s not easy and often either prevents me from getting content out
  or seriously delays it. I&#39;d like to be able to share spur of the moment
  insights and snippets easily and quickly, in the hopes that I end up getting
  a larger amount of content out and in public. That too is good practice!

So please bear with me; thoughts might not be as fully-formed, spelling might
not be well-checked, grammar will be okay at best. This is an experiment! I&#39;m
hoping the content itself can earn its keep despite these potential pitfalls.

Also I like exclamation points and will probably use more of them here than my
normal blog! No more censorship!


## Forest

As I add these lab notes to the nav of my main site, they are replacing a link
to my &quot;forest&quot; â€” an attempt at a digital garden I made a few months ago.
Recently it has become less of a garden and more of a small, static grove of
trees. So instead of pointing to it so directly, I&#39;m moving the link here.
Please enjoy! [forest.inclouds.space](https://forest.inclouds.space/)</description>
        <guid isPermaLink="false">inclouds-space-20230527</guid>
      </item>

  </channel>
</rss>
